{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Minst 手写数字识别\n",
    "\n",
    "## 单层神经网络建模"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 载入数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# 获取 Mints手写数字数据集\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "# 训练数据，测试数据\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 划分验证集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# 训练集总数，以次数据为准将训练集划分为训练集与验证集\n",
    "total_num = len(train_images)\n",
    "\n",
    "# 验证集占训练集的比例\n",
    "valid_split = 0.2\n",
    "\n",
    "# 实际训练集数量\n",
    "train_num = int(total_num * (1 - valid_split))\n",
    "\n",
    "# 训练集（0% ~ 80%）\n",
    "train_x = train_images[:train_num]\n",
    "train_y = train_labels[:train_num]\n",
    "\n",
    "# 剩余部分为验证集（80% ~ 100%）\n",
    "valid_x = train_images[train_num:]\n",
    "valid_y = train_labels[train_num:]\n",
    "\n",
    "test_x = test_images\n",
    "test_y = test_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据降维"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# 把（28，28）的结构拉直为 1行 784列\n",
    "# -1代表由系统计算行数，指定列数为784列\n",
    "train_x = train_x.reshape(-1, 784)\n",
    "valid_x = valid_x.reshape(-1, 784)\n",
    "test_x = test_x.reshape(-1, 784)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 特征数据归一化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "train_x = tf.cast(train_x / 255.0, tf.float32)\n",
    "valid_x = tf.cast(valid_x / 255.0, tf.float32)\n",
    "test_x = tf.cast(test_x / 255.0, tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 独热编码"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# 对标签数据进行独热编码\n",
    "train_y = tf.one_hot(train_y, depth=10)\n",
    "valid_y = tf.one_hot(valid_y, depth=10)\n",
    "test_y = tf.one_hot(test_y, depth=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 创建待优化变量"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# 输入（784） -> 第一层隐层（64） -> 输出层（10）\n",
    "# 定义第一层隐藏层权重和偏置项变量\n",
    "Input_Dim = 784\n",
    "H1_NN = 64\n",
    "\n",
    "W1 = tf.Variable(tf.random.normal([Input_Dim, H1_NN], mean=0.0, stddev=1.0, dtype=tf.float32))\n",
    "B1 = tf.Variable(tf.zeros([H1_NN]), dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# 定义输出层权重和偏置项变量\n",
    "Output_Dim = 10\n",
    "\n",
    "W2 = tf.Variable(tf.random.normal([H1_NN, Output_Dim], mean=0.0, stddev=1.0, dtype=tf.float32))\n",
    "B2 = tf.Variable(tf.zeros([Output_Dim]), dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# 建立待优化列表\n",
    "W = [W1, W2]\n",
    "B = [B1, B2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义模型前向计算"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# 扩展多分类模型\n",
    "# 模型计算后进行Softmax分类，决定属于哪个标签分类（本例为10分类）\n",
    "def model(x, w, b):\n",
    "    x = tf.matmul(x, w[0]) + b[0]\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.matmul(x, w[1]) + b[1]\n",
    "    pred = tf.nn.softmax(x)\n",
    "\n",
    "    # 返回预测标签值\n",
    "    return pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义交叉熵函数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# 定义交叉熵损失函数\n",
    "def loss(x, y, w, b):\n",
    "    # 前向计算\n",
    "    pred = model(x, w, b)\n",
    "\n",
    "    # 计算模型预测值与真实值差异\n",
    "    loss_ = tf.keras.losses.categorical_crossentropy(y_true=y, y_pred=pred)\n",
    "\n",
    "    # 求均方差\n",
    "    return tf.reduce_mean(loss_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 设置训练参数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "train_epochs = 20\n",
    "batch_size = 50\n",
    "learning_rate = 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义梯度计算函数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# 计算样本数据[x, y]在参数[w, b]上的梯度\n",
    "def grad(x, y, w, b):\n",
    "    var_list = w + b\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_ = loss(x, y, w, b)\n",
    "\n",
    "    # 返回梯度向量\n",
    "    return tape.gradient(loss_, var_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 选择优化器"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Adam优化器\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义准确率"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def accuracy(x, y, w, b):\n",
    "    # 计算模型预测标签值与标签值的差异\n",
    "    pred = model(x, w, b)\n",
    "\n",
    "    # 检查预测类别tf.argmax(pred, 1)与实际类别tf.argmax(y, 1)的匹配情况\n",
    "    # 匹配成功返回 True\n",
    "    # 匹配失败返回 False\n",
    "    correct_predication = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "    # 将匹配结果转换为float32输出，得出准确率\n",
    "    return tf.reduce_mean(tf.cast(correct_predication, tf.float32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch =   1, Train_loss = 5.3776, Train_acc = 5.252128, Val_loss = 0.6315, Val_acc = 0.6391\n",
      "Epoch =   2, Train_loss = 4.6154, Train_acc = 4.539206, Val_loss = 0.6885, Val_acc = 0.6916\n",
      "Epoch =   3, Train_loss = 4.3253, Train_acc = 4.278510, Val_loss = 0.7100, Val_acc = 0.7137\n",
      "Epoch =   4, Train_loss = 4.1500, Train_acc = 4.156221, Val_loss = 0.7239, Val_acc = 0.7229\n",
      "Epoch =   5, Train_loss = 2.9688, Train_acc = 2.967189, Val_loss = 0.7905, Val_acc = 0.7924\n",
      "Epoch =   6, Train_loss = 2.5295, Train_acc = 2.587363, Val_loss = 0.8245, Val_acc = 0.8183\n",
      "Epoch =   7, Train_loss = 2.4331, Train_acc = 2.531339, Val_loss = 0.8309, Val_acc = 0.8227\n",
      "Epoch =   8, Train_loss = 2.3510, Train_acc = 2.460204, Val_loss = 0.8379, Val_acc = 0.8269\n",
      "Epoch =   9, Train_loss = 2.2829, Train_acc = 2.417430, Val_loss = 0.8437, Val_acc = 0.8305\n",
      "Epoch =  10, Train_loss = 2.2458, Train_acc = 2.393731, Val_loss = 0.8462, Val_acc = 0.8335\n",
      "Epoch =  11, Train_loss = 2.1997, Train_acc = 2.358518, Val_loss = 0.8491, Val_acc = 0.8363\n",
      "Epoch =  12, Train_loss = 2.1586, Train_acc = 2.331089, Val_loss = 0.8529, Val_acc = 0.8384\n",
      "Epoch =  13, Train_loss = 2.1241, Train_acc = 2.308603, Val_loss = 0.8553, Val_acc = 0.8394\n",
      "Epoch =  14, Train_loss = 2.0980, Train_acc = 2.289169, Val_loss = 0.8571, Val_acc = 0.8406\n",
      "Epoch =  15, Train_loss = 2.0788, Train_acc = 2.275146, Val_loss = 0.8583, Val_acc = 0.8411\n",
      "Epoch =  16, Train_loss = 2.0375, Train_acc = 2.249663, Val_loss = 0.8626, Val_acc = 0.8432\n",
      "Epoch =  17, Train_loss = 2.0201, Train_acc = 2.238000, Val_loss = 0.8634, Val_acc = 0.8447\n",
      "Epoch =  18, Train_loss = 2.0139, Train_acc = 2.230430, Val_loss = 0.8636, Val_acc = 0.8448\n",
      "Epoch =  19, Train_loss = 1.9769, Train_acc = 2.202626, Val_loss = 0.8678, Val_acc = 0.8464\n",
      "Epoch =  20, Train_loss = 1.9567, Train_acc = 2.203668, Val_loss = 0.8698, Val_acc = 0.8470\n"
     ]
    }
   ],
   "source": [
    "total_step = int(train_num / batch_size)\n",
    "\n",
    "loss_list_train = []\n",
    "loss_list_valid = []\n",
    "acc_list_train = []\n",
    "acc_list_valid = []\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    for step in range(total_step):\n",
    "        xs = train_x[step * batch_size:(step + 1) * batch_size]\n",
    "        ys = train_y[step * batch_size:(step + 1) * batch_size]\n",
    "\n",
    "        grads = grad(xs, ys, W, B)\n",
    "        optimizer.apply_gradients(zip(grads, W + B))\n",
    "\n",
    "    loss_train = loss(train_x, train_y, W, B).numpy()\n",
    "    loss_valid = loss(valid_x, valid_y, W, B).numpy()\n",
    "    acc_train = accuracy(train_x, train_y, W, B).numpy()\n",
    "    acc_valid = accuracy(valid_x, valid_y, W, B).numpy()\n",
    "\n",
    "    loss_list_train.append(loss_train)\n",
    "    loss_list_valid.append(loss_valid)\n",
    "\n",
    "    acc_list_train.append(acc_train)\n",
    "    acc_list_valid.append(acc_valid)\n",
    "\n",
    "    print(\"Epoch = {:3d}, \"\n",
    "          \"Train_loss = {:.4f},\"\n",
    "          \" Train_acc = {:4f},\"\n",
    "          \" Val_loss = {:.4f}, \"\n",
    "          \"Val_acc = {:.4f}\".format(epoch + 1,\n",
    "                                    loss_train,\n",
    "                                    loss_valid,\n",
    "                                    acc_train,\n",
    "                                    acc_valid))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}