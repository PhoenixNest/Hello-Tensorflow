{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Minst 手写数字识别\n",
    "\n",
    "## 多层神经网络建模"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 载入数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 获取 Mints手写数字数据集\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "# 训练数据，测试数据\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 划分验证集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 训练集总数，以次数据为准将训练集划分为训练集与验证集\n",
    "total_num = len(train_images)\n",
    "\n",
    "# 验证集占训练集的比例\n",
    "valid_split = 0.2\n",
    "\n",
    "# 实际训练集数量\n",
    "train_num = int(total_num * (1 - valid_split))\n",
    "\n",
    "# 训练集（0% ~ 80%）\n",
    "train_x = train_images[:train_num]\n",
    "train_y = train_labels[:train_num]\n",
    "\n",
    "# 剩余部分为验证集（80% ~ 100%）\n",
    "valid_x = train_images[train_num:]\n",
    "valid_y = train_labels[train_num:]\n",
    "\n",
    "test_x = test_images\n",
    "test_y = test_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据降维"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 把（28，28）的结构拉直为 1行 784列\n",
    "# -1代表由系统计算行数，指定列数为784列\n",
    "train_x = train_x.reshape(-1, 784)\n",
    "valid_x = valid_x.reshape(-1, 784)\n",
    "test_x = test_x.reshape(-1, 784)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 特征数据归一化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_x = tf.cast(train_x / 255.0, tf.float32)\n",
    "valid_x = tf.cast(valid_x / 255.0, tf.float32)\n",
    "test_x = tf.cast(test_x / 255.0, tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 独热编码"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 对标签数据进行独热编码\n",
    "train_y = tf.one_hot(train_y, depth=10)\n",
    "valid_y = tf.one_hot(valid_y, depth=10)\n",
    "test_y = tf.one_hot(test_y, depth=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 创建待优化变量"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 输入（784） -> 第一层隐层（64） -> 输出层（10）\n",
    "# 定义第一层隐藏层权重和偏置项变量\n",
    "Input_Dim = 784\n",
    "H1_NN = 64\n",
    "\n",
    "W1 = tf.Variable(tf.random.normal([Input_Dim, H1_NN], mean=0.0, stddev=1.0, dtype=tf.float32))\n",
    "B1 = tf.Variable(tf.zeros([H1_NN]), dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 定义第二层隐藏层权重和偏置项变量\n",
    "H2_NN = 32\n",
    "\n",
    "W2 = tf.Variable(tf.random.normal([H1_NN, H2_NN], mean=0.0, stddev=1.0, dtype=tf.float32))\n",
    "B2 = tf.Variable(tf.zeros([H2_NN]), dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# 定义输出层权重和偏置项变量\n",
    "Output_Dim = 10\n",
    "\n",
    "W3 = tf.Variable(tf.random.normal([H2_NN, Output_Dim], mean=0.0, stddev=1.0, dtype=tf.float32))\n",
    "B3 = tf.Variable(tf.zeros([Output_Dim]), dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# 建立待优化列表\n",
    "W = [W1, W2, W3]\n",
    "B = [B1, B2, B3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义模型前向计算"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# 扩展多分类模型\n",
    "# 模型计算后进行Softmax分类，决定属于哪个标签分类（本例为10分类）\n",
    "def model(x, w, b):\n",
    "    x = tf.matmul(x, w[0]) + b[0]\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.matmul(x, w[1]) + b[1]\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.matmul(x, w[2]) + b[2]\n",
    "    pred = tf.nn.softmax(x)\n",
    "\n",
    "    # 返回预测标签值\n",
    "    return pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义交叉熵函数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# 定义交叉熵损失函数\n",
    "def loss(x, y, w, b):\n",
    "    # 前向计算\n",
    "    pred = model(x, w, b)\n",
    "\n",
    "    # 计算模型预测值与真实值差异\n",
    "    loss_ = tf.keras.losses.categorical_crossentropy(y_true=y, y_pred=pred)\n",
    "\n",
    "    # 求均方差\n",
    "    return tf.reduce_mean(loss_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 设置训练参数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "train_epochs = 20\n",
    "batch_size = 50\n",
    "learning_rate = 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义梯度计算函数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# 计算样本数据[x, y]在参数[w, b]上的梯度\n",
    "def grad(x, y, w, b):\n",
    "    var_list = w + b\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_ = loss(x, y, w, b)\n",
    "\n",
    "    # 返回梯度向量\n",
    "    return tape.gradient(loss_, var_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 选择优化器"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Adam优化器\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义准确率"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def accuracy(x, y, w, b):\n",
    "    # 计算模型预测标签值与标签值的差异\n",
    "    pred = model(x, w, b)\n",
    "\n",
    "    # 检查预测类别tf.argmax(pred, 1)与实际类别tf.argmax(y, 1)的匹配情况\n",
    "    # 匹配成功返回 True\n",
    "    # 匹配失败返回 False\n",
    "    correct_predication = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "    # 将匹配结果转换为float32输出，得出准确率\n",
    "    return tf.reduce_mean(tf.cast(correct_predication, tf.float32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch =   1, Train_loss = 10.9174, Train_acc = 10.893991, Val_loss = 0.3152, Val_acc = 0.3175\n",
      "Epoch =   2, Train_loss = 9.7280, Train_acc = 9.659597, Val_loss = 0.3909, Val_acc = 0.3952\n",
      "Epoch =   3, Train_loss = 9.2479, Train_acc = 9.249901, Val_loss = 0.4220, Val_acc = 0.4220\n",
      "Epoch =   4, Train_loss = 9.0895, Train_acc = 9.087481, Val_loss = 0.4326, Val_acc = 0.4326\n",
      "Epoch =   5, Train_loss = 8.9697, Train_acc = 8.980812, Val_loss = 0.4405, Val_acc = 0.4395\n",
      "Epoch =   6, Train_loss = 7.6427, Train_acc = 7.624354, Val_loss = 0.5219, Val_acc = 0.5228\n",
      "Epoch =   7, Train_loss = 7.4356, Train_acc = 7.471794, Val_loss = 0.5359, Val_acc = 0.5337\n",
      "Epoch =   8, Train_loss = 7.3411, Train_acc = 7.396438, Val_loss = 0.5420, Val_acc = 0.5377\n",
      "Epoch =   9, Train_loss = 7.2957, Train_acc = 7.333180, Val_loss = 0.5449, Val_acc = 0.5420\n",
      "Epoch =  10, Train_loss = 7.2502, Train_acc = 7.284460, Val_loss = 0.5476, Val_acc = 0.5450\n",
      "Epoch =  11, Train_loss = 7.2289, Train_acc = 7.278317, Val_loss = 0.5496, Val_acc = 0.5452\n",
      "Epoch =  12, Train_loss = 7.2282, Train_acc = 7.287966, Val_loss = 0.5492, Val_acc = 0.5453\n",
      "Epoch =  13, Train_loss = 7.1484, Train_acc = 7.186262, Val_loss = 0.5547, Val_acc = 0.5516\n",
      "Epoch =  14, Train_loss = 7.1335, Train_acc = 7.179941, Val_loss = 0.5556, Val_acc = 0.5522\n",
      "Epoch =  15, Train_loss = 7.1150, Train_acc = 7.174803, Val_loss = 0.5568, Val_acc = 0.5533\n",
      "Epoch =  16, Train_loss = 7.0923, Train_acc = 7.151593, Val_loss = 0.5585, Val_acc = 0.5547\n",
      "Epoch =  17, Train_loss = 7.1109, Train_acc = 7.143173, Val_loss = 0.5566, Val_acc = 0.5544\n",
      "Epoch =  18, Train_loss = 7.0647, Train_acc = 7.135336, Val_loss = 0.5601, Val_acc = 0.5545\n",
      "Epoch =  19, Train_loss = 7.0606, Train_acc = 7.135225, Val_loss = 0.5604, Val_acc = 0.5553\n",
      "Epoch =  20, Train_loss = 7.0208, Train_acc = 7.105691, Val_loss = 0.5632, Val_acc = 0.5570\n"
     ]
    }
   ],
   "source": [
    "total_step = int(train_num / batch_size)\n",
    "\n",
    "loss_list_train = []\n",
    "loss_list_valid = []\n",
    "acc_list_train = []\n",
    "acc_list_valid = []\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    for step in range(total_step):\n",
    "        xs = train_x[step * batch_size:(step + 1) * batch_size]\n",
    "        ys = train_y[step * batch_size:(step + 1) * batch_size]\n",
    "\n",
    "        grads = grad(xs, ys, W, B)\n",
    "        optimizer.apply_gradients(zip(grads, W + B))\n",
    "\n",
    "    loss_train = loss(train_x, train_y, W, B).numpy()\n",
    "    loss_valid = loss(valid_x, valid_y, W, B).numpy()\n",
    "    acc_train = accuracy(train_x, train_y, W, B).numpy()\n",
    "    acc_valid = accuracy(valid_x, valid_y, W, B).numpy()\n",
    "\n",
    "    loss_list_train.append(loss_train)\n",
    "    loss_list_valid.append(loss_valid)\n",
    "\n",
    "    acc_list_train.append(acc_train)\n",
    "    acc_list_valid.append(acc_valid)\n",
    "\n",
    "    print(\"Epoch = {:3d}, \"\n",
    "          \"Train_loss = {:.4f},\"\n",
    "          \" Train_acc = {:4f},\"\n",
    "          \" Val_loss = {:.4f}, \"\n",
    "          \"Val_acc = {:.4f}\".format(epoch + 1,\n",
    "                                    loss_train,\n",
    "                                    loss_valid,\n",
    "                                    acc_train,\n",
    "                                    acc_valid))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}