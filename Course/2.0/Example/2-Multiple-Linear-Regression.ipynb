{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 多元线性回归\n",
    "\n",
    "## 波士顿房价问题"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "|       |                       |         |                  |\n",
    "|:-----:|:---------------------:|:-------:|:----------------:|\n",
    "| CRIM  |        城镇人均犯罪率        |   AGE   | 1940年之前建成的自用房屋比例 |\n",
    "|  ZN   | 住宅用地超过25000 sq.ft 的比例 |   DIS   | 到波士顿5个中心区域的加权距离  |\n",
    "| INDUS |     城镇非零售商用土地的比例      |   RAD   |    辐射性公路的靠近指数    |\n",
    "| CHAS  |     边界是河流为1，否则为0      |   TAX   | 每10000美元的全值财产税率  |\n",
    "|  NOX  |        一氧化氮浓度         | PTRATIO |      城镇师生比例      |\n",
    "|  RM   |        住宅平均房间数        |  LSTAT  |   人口中地位低下者的比例    |\n",
    "|       |                       |  MEDV   | 自主房的平均房价，单位：千美元  |"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             CRIM         ZN       INDUS         CHAS         NOX          RM  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
      "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
      "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
      "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
      "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
      "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
      "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
      "\n",
      "              AGE         DIS         RAD         TAX     PTRATIO       LSTAT  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean    68.574901    3.795043    9.549407  408.237154   18.455534   12.653063   \n",
      "std     28.148861    2.105710    8.707259  168.537116    2.164946    7.141062   \n",
      "min      2.900000    1.129600    1.000000  187.000000   12.600000    1.730000   \n",
      "25%     45.025000    2.100175    4.000000  279.000000   17.400000    6.950000   \n",
      "50%     77.500000    3.207450    5.000000  330.000000   19.050000   11.360000   \n",
      "75%     94.075000    5.188425   24.000000  666.000000   20.200000   16.955000   \n",
      "max    100.000000   12.126500   24.000000  711.000000   22.000000   37.970000   \n",
      "\n",
      "             MEDV  \n",
      "count  506.000000  \n",
      "mean    22.532806  \n",
      "std      9.197104  \n",
      "min      5.000000  \n",
      "25%     17.025000  \n",
      "50%     21.200000  \n",
      "75%     25.000000  \n",
      "max     50.000000  \n"
     ]
    }
   ],
   "source": [
    "# 读取数据文件\n",
    "df = pd.read_csv(\"Data/boston.csv\", header=0)\n",
    "\n",
    "# 显示数据摘要信息\n",
    "print(df.describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CRIM   ZN   INDUS   CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
      "0    0.00632  18.0    2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
      "1    0.02731   0.0    7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
      "2    0.02729   0.0    7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
      "3    0.03237   0.0    2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
      "4    0.06905   0.0    2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
      "..       ...   ...     ...   ...    ...    ...   ...     ...  ...  ...   \n",
      "501  0.06263   0.0   11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
      "502  0.04527   0.0   11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
      "503  0.06076   0.0   11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
      "504  0.10959   0.0   11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
      "505  0.04741   0.0   11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
      "\n",
      "     PTRATIO  LSTAT  MEDV  \n",
      "0       15.3   4.98  24.0  \n",
      "1       17.8   9.14  21.6  \n",
      "2       17.8   4.03  34.7  \n",
      "3       18.7   2.94  33.4  \n",
      "4       18.7   5.33  36.2  \n",
      "..       ...    ...   ...  \n",
      "501     21.0   9.67  22.4  \n",
      "502     21.0   9.08  20.6  \n",
      "503     21.0   5.64  23.9  \n",
      "504     21.0   6.48  22.0  \n",
      "505     21.0   7.88  11.9  \n",
      "\n",
      "[506 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# 显示所有数据\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [
    {
     "data": {
      "text/plain": "      CRIM   ZN   INDUS   CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n0  0.00632  18.0    2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n1  0.02731   0.0    7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n2  0.02729   0.0    7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n\n   LSTAT  MEDV  \n0   4.98  24.0  \n1   9.14  21.6  \n2   4.03  34.7  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>LSTAT</th>\n      <th>MEDV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00632</td>\n      <td>18.0</td>\n      <td>2.31</td>\n      <td>0</td>\n      <td>0.538</td>\n      <td>6.575</td>\n      <td>65.2</td>\n      <td>4.0900</td>\n      <td>1</td>\n      <td>296</td>\n      <td>15.3</td>\n      <td>4.98</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02731</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0</td>\n      <td>0.469</td>\n      <td>6.421</td>\n      <td>78.9</td>\n      <td>4.9671</td>\n      <td>2</td>\n      <td>242</td>\n      <td>17.8</td>\n      <td>9.14</td>\n      <td>21.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.02729</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0</td>\n      <td>0.469</td>\n      <td>7.185</td>\n      <td>61.1</td>\n      <td>4.9671</td>\n      <td>2</td>\n      <td>242</td>\n      <td>17.8</td>\n      <td>4.03</td>\n      <td>34.7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只显示前3条数据\n",
    "df.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "data": {
      "text/plain": "        CRIM   ZN   INDUS   CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n503  0.06076   0.0   11.93     0  0.573  6.976  91.0  2.1675    1  273   \n504  0.10959   0.0   11.93     0  0.573  6.794  89.3  2.3889    1  273   \n505  0.04741   0.0   11.93     0  0.573  6.030  80.8  2.5050    1  273   \n\n     PTRATIO  LSTAT  MEDV  \n503     21.0   5.64  23.9  \n504     21.0   6.48  22.0  \n505     21.0   7.88  11.9  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>LSTAT</th>\n      <th>MEDV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>503</th>\n      <td>0.06076</td>\n      <td>0.0</td>\n      <td>11.93</td>\n      <td>0</td>\n      <td>0.573</td>\n      <td>6.976</td>\n      <td>91.0</td>\n      <td>2.1675</td>\n      <td>1</td>\n      <td>273</td>\n      <td>21.0</td>\n      <td>5.64</td>\n      <td>23.9</td>\n    </tr>\n    <tr>\n      <th>504</th>\n      <td>0.10959</td>\n      <td>0.0</td>\n      <td>11.93</td>\n      <td>0</td>\n      <td>0.573</td>\n      <td>6.794</td>\n      <td>89.3</td>\n      <td>2.3889</td>\n      <td>1</td>\n      <td>273</td>\n      <td>21.0</td>\n      <td>6.48</td>\n      <td>22.0</td>\n    </tr>\n    <tr>\n      <th>505</th>\n      <td>0.04741</td>\n      <td>0.0</td>\n      <td>11.93</td>\n      <td>0</td>\n      <td>0.573</td>\n      <td>6.030</td>\n      <td>80.8</td>\n      <td>2.5050</td>\n      <td>1</td>\n      <td>273</td>\n      <td>21.0</td>\n      <td>7.88</td>\n      <td>11.9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只显示后3条数据\n",
    "df.tail(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "# 获取数据集的值，df.values将以np.array形式返回数据集的值\n",
    "ds = df.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "# 查看数据形状\n",
    "# 506行，13列的二维数组\n",
    "print(ds.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 4.9800e+00 2.4000e+01]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 9.1400e+00 2.1600e+01]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 4.0300e+00 3.4700e+01]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 5.6400e+00 2.3900e+01]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 6.4800e+00 2.2000e+01]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 7.8800e+00 1.1900e+01]]\n"
     ]
    }
   ],
   "source": [
    "# 查看数据集的值\n",
    "print(ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 特征数据归一化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [],
   "source": [
    "# 如有以下例子：\n",
    "# 制作一份鸡汤，需要用到鸡、水、姜、葱、蒜、盐等材料，但材料间的取值范围均不相同\n",
    "# 水的取值范围可能在2000克到3000克，但相比较之下盐可能仅需要1克2克，这样的取值范围在多元线性回归中是不合理的\n",
    "#\n",
    "# 为防止不同特征值取值范围之间的差异性，需要对特征数据进行归一化\n",
    "# 归一化过程：[特征值 / max(特征值) - min(特征值)]\n",
    "\n",
    "# x_data 为前12列特征数据\n",
    "x_data = ds[:, :12]  # [:, :12]表示从0~11列\n",
    "\n",
    "# y_data 为最后1列标签数据\n",
    "y_data = ds[:, 12]  # [:, 12]表示第12列\n",
    "\n",
    "# 对特征数据【0到11】列进行归一化（缩小差异区间至0~1）处理\n",
    "for i in range(12):\n",
    "    x_data[:, i] = x_data[:, i] / (x_data[:, i].max() - x_data[:, i].min())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.10352762e-05 1.80000000e-01 8.46774194e-02 ... 5.64885496e-01\n",
      "  1.62765957e+00 1.37417219e-01]\n",
      " [3.06957815e-04 0.00000000e+00 2.59164223e-01 ... 4.61832061e-01\n",
      "  1.89361702e+00 2.52207506e-01]\n",
      " [3.06733020e-04 0.00000000e+00 2.59164223e-01 ... 4.61832061e-01\n",
      "  1.89361702e+00 1.11203091e-01]\n",
      " ...\n",
      " [6.82927750e-04 0.00000000e+00 4.37316716e-01 ... 5.20992366e-01\n",
      "  2.23404255e+00 1.55629139e-01]\n",
      " [1.23176518e-03 0.00000000e+00 4.37316716e-01 ... 5.20992366e-01\n",
      "  2.23404255e+00 1.78807947e-01]\n",
      " [5.32876969e-04 0.00000000e+00 4.37316716e-01 ... 5.20992366e-01\n",
      "  2.23404255e+00 2.17439294e-01]] \n",
      " shape = (506, 12)\n"
     ]
    }
   ],
   "source": [
    "print(x_data, \"\\n shape =\", x_data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9] \n",
      " shape = (506,)\n"
     ]
    }
   ],
   "source": [
    "print(y_data, \"\\n shape =\", y_data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 划分数据集：训练集、验证集和测试集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [],
   "source": [
    "# 训练集\n",
    "train_num = 300\n",
    "\n",
    "# 验证集\n",
    "valid_num = 100\n",
    "\n",
    "# 测试集 = 106 = 506 - 训练集数目 - 验证集数目\n",
    "test_num = len(x_data) - train_num - valid_num\n",
    "\n",
    "# 训练集划分（0 ~ 299）\n",
    "x_train = x_data[:train_num]\n",
    "y_train = y_data[:train_num]\n",
    "\n",
    "# 验证集划分（300 ~ 399）\n",
    "x_valid = x_data[train_num: train_num + valid_num]\n",
    "y_valid = y_data[train_num: train_num + valid_num]\n",
    "\n",
    "# 测试集划分（400 ~ 506）\n",
    "x_test = x_data[train_num + valid_num: train_num + valid_num + test_num]\n",
    "y_test = y_data[train_num + valid_num: train_num + valid_num + test_num]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [],
   "source": [
    "# 数据类型转换，方便后面求损失函时要和变量W执行tf.matmul操作\n",
    "# 使用sklearn库中的归一化函数能起到与上面人工归一化操作一样的结果\n",
    "x_train = tf.cast(scale(x_train), dtype=tf.float32)\n",
    "x_valid = tf.cast(scale(x_valid), dtype=tf.float32)\n",
    "x_test = tf.cast(scale(x_test), dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 构建模型\n",
    "\n",
    "多元线性回归模型仍然是简单的线性函数，其基本形式还是：y = wx + b，只是此处w和b不再是一个标量，而是执行矩阵相乘，此处调用tf.matmul()函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "def model(x, w, b):\n",
    "    return tf.matmul(x, w) + b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 创建变量"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [],
   "source": [
    "# 矩阵相乘乘数\n",
    "# 均值mean为0，标准差为1\n",
    "W = tf.Variable(tf.random.normal([12, 1], mean=0.0, stddev=1.0, dtype=tf.float32))\n",
    "\n",
    "# 偏置项\n",
    "B = tf.Variable(tf.zeros(1), dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(12, 1) dtype=float32, numpy=\n",
      "array([[-0.9876368 ],\n",
      "       [ 0.0781666 ],\n",
      "       [ 0.45767918],\n",
      "       [ 1.4723794 ],\n",
      "       [ 0.2682287 ],\n",
      "       [ 0.10558725],\n",
      "       [-0.24819334],\n",
      "       [-1.6381028 ],\n",
      "       [-0.47659734],\n",
      "       [-0.9819269 ],\n",
      "       [-0.62423015],\n",
      "       [ 0.90176094]], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(W)\n",
    "print(B)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 设置训练参数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [],
   "source": [
    "training_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 采用小批量梯度下降算法MBGD进行优化\n",
    "# 调整每次进行小批量训练样本数\n",
    "batch_size = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义均方差损失函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [],
   "source": [
    "# 采用均方差作为损失函数\n",
    "def loss(x, y, w, b):\n",
    "    # 计算模型预测值与标签值的差异\n",
    "    err = model(x, w, b) - y\n",
    "\n",
    "    # 求平方，得出方差\n",
    "    squared_err = tf.square(err)\n",
    "\n",
    "    # 求均值，得出均方差\n",
    "    return tf.reduce_mean(squared_err)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义梯度计算函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [],
   "source": [
    "# 计算样本数据[x, y]在参数[w, b]上的梯度\n",
    "def grad(x, y, w, b):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_ = loss(x, y, w, b)\n",
    "\n",
    "    # 返回梯度向量\n",
    "    return tape.gradient(loss_, [w, b])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 选择优化器"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "# 创建优化器，设置学习率\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 迭代训练"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs =   1, Train_loss = 660.6685, Valid_loss = 463.6287\n",
      "Epochs =   2, Train_loss = 595.9728, Valid_loss = 413.2029\n",
      "Epochs =   3, Train_loss = 539.4862, Valid_loss = 370.0386\n",
      "Epochs =   4, Train_loss = 489.7980, Valid_loss = 332.7134\n",
      "Epochs =   5, Train_loss = 445.8968, Valid_loss = 300.2647\n",
      "Epochs =   6, Train_loss = 407.0127, Valid_loss = 271.9940\n",
      "Epochs =   7, Train_loss = 372.5277, Valid_loss = 247.3594\n",
      "Epochs =   8, Train_loss = 341.9265, Valid_loss = 225.9180\n",
      "Epochs =   9, Train_loss = 314.7665, Valid_loss = 207.2929\n",
      "Epochs =  10, Train_loss = 290.6622, Valid_loss = 191.1559\n",
      "Epochs =  11, Train_loss = 269.2729, Valid_loss = 177.2171\n",
      "Epochs =  12, Train_loss = 250.2968, Valid_loss = 165.2182\n",
      "Epochs =  13, Train_loss = 233.4653, Valid_loss = 154.9288\n",
      "Epochs =  14, Train_loss = 218.5388, Valid_loss = 146.1432\n",
      "Epochs =  15, Train_loss = 205.3042, Valid_loss = 138.6777\n",
      "Epochs =  16, Train_loss = 193.5716, Valid_loss = 132.3689\n",
      "Epochs =  17, Train_loss = 183.1720, Valid_loss = 127.0715\n",
      "Epochs =  18, Train_loss = 173.9548, Valid_loss = 122.6564\n",
      "Epochs =  19, Train_loss = 165.7865, Valid_loss = 119.0095\n",
      "Epochs =  20, Train_loss = 158.5480, Valid_loss = 116.0296\n",
      "Epochs =  21, Train_loss = 152.1340, Valid_loss = 113.6278\n",
      "Epochs =  22, Train_loss = 146.4508, Valid_loss = 111.7254\n",
      "Epochs =  23, Train_loss = 141.4152, Valid_loss = 110.2536\n",
      "Epochs =  24, Train_loss = 136.9537, Valid_loss = 109.1515\n",
      "Epochs =  25, Train_loss = 133.0007, Valid_loss = 108.3659\n",
      "Epochs =  26, Train_loss = 129.4985, Valid_loss = 107.8503\n",
      "Epochs =  27, Train_loss = 126.3955, Valid_loss = 107.5639\n",
      "Epochs =  28, Train_loss = 123.6463, Valid_loss = 107.4713\n",
      "Epochs =  29, Train_loss = 121.2106, Valid_loss = 107.5413\n",
      "Epochs =  30, Train_loss = 119.0526, Valid_loss = 107.7470\n",
      "Epochs =  31, Train_loss = 117.1407, Valid_loss = 108.0651\n",
      "Epochs =  32, Train_loss = 115.4468, Valid_loss = 108.4752\n",
      "Epochs =  33, Train_loss = 113.9460, Valid_loss = 108.9596\n",
      "Epochs =  34, Train_loss = 112.6164, Valid_loss = 109.5034\n",
      "Epochs =  35, Train_loss = 111.4384, Valid_loss = 110.0935\n",
      "Epochs =  36, Train_loss = 110.3949, Valid_loss = 110.7185\n",
      "Epochs =  37, Train_loss = 109.4705, Valid_loss = 111.3690\n",
      "Epochs =  38, Train_loss = 108.6516, Valid_loss = 112.0369\n",
      "Epochs =  39, Train_loss = 107.9263, Valid_loss = 112.7151\n",
      "Epochs =  40, Train_loss = 107.2839, Valid_loss = 113.3979\n",
      "Epochs =  41, Train_loss = 106.7149, Valid_loss = 114.0803\n",
      "Epochs =  42, Train_loss = 106.2111, Valid_loss = 114.7583\n",
      "Epochs =  43, Train_loss = 105.7650, Valid_loss = 115.4284\n",
      "Epochs =  44, Train_loss = 105.3702, Valid_loss = 116.0878\n",
      "Epochs =  45, Train_loss = 105.0207, Valid_loss = 116.7343\n",
      "Epochs =  46, Train_loss = 104.7115, Valid_loss = 117.3662\n",
      "Epochs =  47, Train_loss = 104.4379, Valid_loss = 117.9820\n",
      "Epochs =  48, Train_loss = 104.1961, Valid_loss = 118.5807\n",
      "Epochs =  49, Train_loss = 103.9823, Valid_loss = 119.1614\n",
      "Epochs =  50, Train_loss = 103.7934, Valid_loss = 119.7237\n"
     ]
    }
   ],
   "source": [
    "# 用于保存训练集loss值的列表\n",
    "loss_list_train = []\n",
    "\n",
    "# 用户保存验证集loss值的列表\n",
    "loss_list_valid = []\n",
    "\n",
    "total_step = int(train_num / batch_size)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    for step in range(total_step):\n",
    "        xs = x_train[step * batch_size: (step + 1) * batch_size, :]\n",
    "        ys = y_train[step * batch_size: (step + 1) * batch_size]\n",
    "\n",
    "        # 计算梯度\n",
    "        grads = grad(xs, ys, W, B)\n",
    "\n",
    "        # 优化器根据梯度自动调整变量W和B\n",
    "        optimizer.apply_gradients(zip(grads, [W, B]))\n",
    "\n",
    "    # 计算轮当前训练损失\n",
    "    loss_train = loss(x_train, y_train, W, B).numpy()\n",
    "\n",
    "    # 计算当前轮验证损失\n",
    "    loss_valid = loss(x_valid, y_valid, W, B).numpy()\n",
    "\n",
    "    loss_list_train.append(loss_train)\n",
    "    loss_list_valid.append(loss_valid)\n",
    "\n",
    "    print(\"Epochs = {:3d}, Train_loss = {:.4f}, Valid_loss = {:.4f}\".format(epoch + 1, loss_train, loss_valid))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 图形化损失"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x1e948d7bc40>"
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAvDklEQVR4nO3deXwV5d3//9cnG0nYCYtIQFBQq8gaFlGQRbSiEqyiAj8Fl+J2g4VWxfbuV7Ral7qi1n3BuqBWRSouKGLVugIisnkLiAVEBFT2NVy/P645IcYEEnLmTJLzfj4e85g5c86Z6xqM5zPXbs45REREAFKizoCIiFQeCgoiIlJIQUFERAopKIiISCEFBRERKZQWdQYqomHDhq5ly5ZRZ0NEpEqZNWvWWudco5Leq9JBoWXLlsycOTPqbIiIVClm9k1p76n6SERECikoiIhIIQUFEREpVKXbFESketm5cycrVqxg27ZtUWelWsjMzCQ3N5f09PQyf0dBQUQqjRUrVlC7dm1atmyJmUWdnSrNOce6detYsWIFrVq1KvP3VH0kIpXGtm3byMnJUUCIAzMjJyen3KUuBQURqVQUEOJnf/4tkzIofPghXH111LkQEal8kjIozJ4NN90ES5ZEnRMRqSzWrVtHhw4d6NChAwcccADNmjUrfL1jx469fnfmzJmMHj26XOm1bNmStWvXViTLoUjKhuYTTvD7adPgkkuizYuIVA45OTnMmTMHgPHjx1OrVi3+8Ic/FL6/a9cu0tJK/snMy8sjLy8vEdkMXVKWFFq3hoMOgjffjDonIlKZjRgxgosvvphu3bpx5ZVX8sknn3D00UfTsWNHevTowZdffgnAO++8wymnnAL4gHL++efTu3dvDj74YCZMmFDm9JYtW0bfvn1p164d/fr147///S8Azz//PG3btqV9+/b06tULgPnz59O1a1c6dOhAu3bt+Oqrr+Jyz0lZUjCD/v3h+edh1y4oJfiLSIR+9zsIHtzjpkMHuPPO8n1nxYoVfPDBB6SmprJhwwbee+890tLSeOutt/jjH//ICy+88IvvLFq0iBkzZrBx40YOO+wwLrnkkjKNFRg1ahTDhw9n+PDhPProo4wePZrJkydz3XXX8cYbb9CsWTN++uknAO6//34uv/xyhg0bxo4dOygoKCjfjZUiKUsK4IPC+vWg+fREZG8GDx5MamoqAOvXr2fw4MG0bduWMWPGMH/+/BK/c/LJJ1OjRg0aNmxI48aNWb16dZnS+vDDDxk6dCgA55xzDu+//z4AxxxzDCNGjOChhx4q/PE/+uij+etf/8rNN9/MN998Q1ZWVkVvFUjSkgJAv36+xDBtGnTvHnVuRKS48j7Rh6VmzZqFx3/+85/p06cPL730EsuWLaN3794lfqdGjRqFx6mpqezatatCebj//vv5+OOPmTp1Kp07d2bWrFkMHTqUbt26MXXqVAYMGMADDzxA3759K5QOJHFJIScHOndWu4KIlN369etp1qwZAI8//njcr9+jRw8mTZoEwFNPPUXPnj0BWLJkCd26deO6666jUaNGLF++nKVLl3LwwQczevRo8vPzmTt3blzykLRBAXwV0kcfwcaNUedERKqCK6+8kquvvpqOHTtW+OkfoF27duTm5pKbm8vYsWO5++67eeyxx2jXrh3/+Mc/uOuuuwC44oorOOqoo2jbti09evSgffv2PPfcc7Rt25YOHTowb948zj333ArnB8Ccc3G5UBTy8vJcRRbZmTED+vaFKVPg1FPjmDER2S8LFy7kV7/6VdTZqFZK+jc1s1nOuRL70CZ1SaFHD8jO9u0KIiKS5EGhRg047ji1K4iIxCR1UADfrvDllxCMERERSWoKCv39XqUFEREFBY48Epo2VVAQEQEFhcIpL6ZPh927o86NiEi0kj4ogA8Ka9fGf54VEala+vTpwxtvvPGzc3feeSeX7GU65d69exPrGj9gwIDCuYmKGj9+PLfeemuZz0dJQQE4/ni/V9dUkeQ2ZMiQwhHFMZMmTWLIkCFl+v6rr75KvXr1QshZ4igoAAccAEcdpXYFkWR3xhlnMHXq1MJFdZYtW8a3335Lz549ueSSS8jLy+PII4/kmmuuKfH7RRfOueGGGzj00EM59thjC6fYLgvnHFdccQVt27blqKOO4tlnnwVg1apV9OrViw4dOtC2bVvee+89CgoKGDFiROFn77jjjgr+CyTxhHjFnXAC3H03bNniB7SJSMQimDu7QYMGdO3alddee438/HwmTZrEmWeeiZlxww030KBBAwoKCujXrx9z586lXbt2JV5n1qxZTJo0iTlz5rBr1y46depE586dy5TFF198kTlz5vD555+zdu1aunTpQq9evXj66ac58cQT+dOf/kRBQQFbtmxhzpw5rFy5knnz5gGUWHVVXqGWFMysnpn908wWmdlCMzvazBqY2Ztm9lWwrx981sxsgpktNrO5ZtYpzLwV178/7NgB772XyFRFpLIpWoVUtOroueeeo1OnTnTs2JH58+ezYMGCUq/x3nvvcdppp5GdnU2dOnUYOHBgmdN///33GTJkCKmpqTRp0oTjjjuOTz/9lC5duvDYY48xfvx4vvjiC2rXrs3BBx/M0qVLGTVqFK+//jp16tSp2M0TfknhLuB159wZZpYBZAN/BKY7524ys3HAOOAq4CSgTbB1A+4L9gnRsydkZPh2hRNPTFSqIlKqiObOzs/PZ8yYMcyePZstW7bQuXNnvv76a2699VY+/fRT6tevz4gRI9i2bVtC89WrVy/effddpk6dyogRIxg7diznnnsun3/+OW+88Qb3338/zz33HI8++miF0gmtpGBmdYFewCMAzrkdzrmfgHxgYvCxicCg4DgfeMJ5HwH1zKxpWPkrLjsbjj1W7Qoiya5WrVr06dOH888/v7CUsGHDBmrWrEndunVZvXo1r7322l6v0atXLyZPnszWrVvZuHEj//rXv8qcfs+ePXn22WcpKChgzZo1vPvuu3Tt2pVvvvmGJk2a8Nvf/pYLL7yQ2bNns3btWnbv3s3pp5/O9ddfz+zZsyt07xBuSaEVsAZ4zMzaA7OAy4EmzrlVwWe+A5oEx82A5UW+vyI4t6rIOcxsJDASoEWLFnHN8AknwLhxsGqVH9AmIslpyJAhnHbaaYXVSO3bt6djx44cfvjhNG/enGOOOWav3+/UqRNnnXUW7du3p3HjxnTp0qXUz15//fXcWaRUtHz5cj788EPat2+PmXHLLbdwwAEHMHHiRP72t7+Rnp5OrVq1eOKJJ1i5ciXnnXceu4NBVjfeeGOF7z20qbPNLA/4CDjGOfexmd0FbABGOefqFfncj865+mb2CnCTc+794Px04CrnXKlzY1d06uzi5syBjh3hkUfg/PPjdlkRKSNNnR1/lWnq7BXACufcx8HrfwKdgNWxaqFg/33w/kqgeZHv5wbnEqZ9e2jRAl5+OZGpiohUHqEFBefcd8ByMzssONUPWABMAYYH54YDsZ/gKcC5QS+k7sD6ItVMCWEGAwf6doUtWxKZsohI5RD24LVRwFNmNhfoAPwVuAnob2ZfAccHrwFeBZYCi4GHgEtDzluJBg2CrVvV4CwSlaq8GmRlsz//lqF2SXXOzQFKqrfqV8JnHXBZmPkpi169oF49mDwZ8vOjzo1IcsnMzGTdunXk5ORgZlFnp0pzzrFu3ToyMzPL9T2NaC4mPR0GDIBXXoGCAkhNjTpHIskjNzeXFStWsGbNmqizUi1kZmaSm5tbru8oKJQgPx+efho++MAPahORxEhPT6dVq1ZRZyOpaUK8Evz613508+TJUedERCSxFBRKUKcO9O3ru6aqzUtEkomCQiny82HJEtjLnFciItWOgkIpYpMaqgpJRJKJgkIpDjwQunbV6GYRSS4KCnuRnw+ffgrffht1TkREEkNBYS9ig9emTIk2HyIiiaKgsBdHHAGtW6tdQUSSh4LCXpj50sLbb8OGDVHnRkQkfAoK+5CfDzt3wuuvR50TEZHwKSjsQ48e0LChqpBEJDkoKOxDaiqceiq8+qovMYiIVGcKCmWQnw/r18O//x11TkREwqWgUAb9+0N2Njz/fNQ5EREJl4JCGWRn+xXZnn8eduyIOjciIuFRUCijoUPhxx/hjTeizomISHgUFMrohBMgJ8cvviMiUl0pKJRRejoMHuwnyNu0KerciIiEQ0GhHIYNg61bNXOqiFRfCgrl0KMHtGihKiQRqb4UFMohJQWGDPGNzWvWRJ0bEZH4U1Aop6FDoaAA/vnPqHMiIhJ/CgrldNRRcOSR8NRTUedERCT+FBTKycw3OP/nP7BsWdS5ERGJr1CDgpktM7MvzGyOmc0MzjUwszfN7KtgXz84b2Y2wcwWm9lcM+sUZt4q4uyz/X7SpGjzISISb4koKfRxznVwzuUFr8cB051zbYDpwWuAk4A2wTYSuC8BedsvrVr5nkjqhSQi1U0U1Uf5wMTgeCIwqMj5J5z3EVDPzJpGkL8yGToUvvjCbyIi1UXYQcEB08xslpmNDM41cc6tCo6/A5oEx82A5UW+uyI49zNmNtLMZprZzDUR9gsdPNivtfDMM5FlQUQk7sIOCsc65zrhq4YuM7NeRd90zjl84Cgz59yDzrk851xeo0aN4pjV8mnc2M+H9PTT4Mp1ByIilVeoQcE5tzLYfw+8BHQFVseqhYL998HHVwLNi3w9NzhXaQ0dCt98Ax9+GHVORETiI7SgYGY1zax27Bg4AZgHTAGGBx8bDsRmEpoCnBv0QuoOrC9SzVQp5edDVhY8+WTUORERiY8wSwpNgPfN7HPgE2Cqc+514Cagv5l9BRwfvAZ4FVgKLAYeAi4NMW9xUbs2/OY3vgppy5aocyMiUnFpYV3YObcUaF/C+XVAvxLOO+CysPITlpEj/ejm55+H4cP3/XkRkcpMI5orqGdPOOwwePDBqHMiIlJxCgoVZOZLCx98APPmRZ0bEZGKUVCIg3PPhYwMeOihqHMiIlIxCgpx0LAhnH46PPGEX5lNRKSqUlCIk5Ej4aeftM6CiFRtCgpxctxx0KaNGpxFpGpLzqDwzjtw6aVxnZ8i1uD8/vuwYEHcLisiklDJGRS++gruuw8++yyulx0+HNLT1eAsIlVXcgaF00/3v95xnuK0USM/wnniRNi2La6XFhFJiOQMCg0awIknwrPPwu7dcb30yJHw44/wwgtxvayISEIkZ1AAv6bm8uV+1Fkc9ekDrVurwVlEqqbkDQqxKU7jXIUUa3B+911YtCiulxYRCV3yBoVateDUU/1Mdrt2xfXSanAWkaoqeYMCwJAhsGYNTJ8e18s2bgynnQaPPQabN8f10iIioUruoHDSSVC3bigLLV9+uW9wfvzxuF9aRCQ0yR0UatTwj/QvvRT3PqQ9ekD37nDHHVBQENdLi4iEJrmDAvgqpA0b4NVX437p3/8eliyBl1/e92dFRCoDBYW+fX0jwKRJcb/0aadBq1Zw221xv7SISCgUFNLSYPBg+Ne/YOPGuF46NRXGjPFDIT76KK6XFhEJhYIC+CqkbdtCqec57zyoV0+lBRGpGhQUAI4+Gpo3D6UXUq1acPHF8OKLsHRp3C8vIhJXCgoAKSl+2otp02DdurhfftQoX5V0551xv7SISFwpKMQMGeJHNoewdNqBB8LQofDoo37sgohIZaWgENOhAxx2WChVSABjx/rRzQ88EMrlRUTiQkEhxsxXIb37LqxcGffLt2sH/fvDhAmwY0fcLy8iEhcKCkUNG+aX6Axpborf/x5WrQqtMCIiUmEKCkW1aQP9+vnFEEKYm+KEE6BtW989NY7LQ4uIxE3oQcHMUs3sMzN7JXjdysw+NrPFZvasmWUE52sErxcH77cMO28luugi+O9/4fXX435pM/jDH+CLL+CVV+J+eRGRCitTUDCzmmaWEhwfamYDzSy9jGlcDiws8vpm4A7nXGvgR+CC4PwFwI/B+TuCzyVefj40aRJai/CwYXDIIXDNNSotiEjlU9aSwrtAppk1A6YB5wCP7+tLZpYLnAw8HLw2oC8Q6/c5ERgUHOcHrwne7xd8PrEyMuCCC2DqVF9iiLO0NPh//w8++0wT5YlI5VPWoGDOuS3Ab4C/O+cGA0eW4Xt3AlcCu4PXOcBPzrnYUmcrgGbBcTNgOUDw/vrg8z/PiNlIM5tpZjPXrFlTxuyX029/6x/jH344lMsPHQqHHupLC7t37/vzIiKJUuagYGZHA8OAqcG51H184RTge+fcrArk7xeccw865/Kcc3mNGjWK56X3aNnSL8Dz8MOwc2fcL5+W5gPC3Ll++gsRkcqirEHhd8DVwEvOuflmdjAwYx/fOQYYaGbLgEn4aqO7gHpmlhZ8JheIDQpYCTQHCN6vC8R/zomyuugi3380pBbhs86CX/3KBwctwiMilUWZgoJz7t/OuYHOuZuDBue1zrnR+/jO1c65XOdcS+Bs4G3n3DB8MDkj+NhwIFazPiV4TfD+285F2BQ7YADk5sL994dy+dRUGD8eFiyA558PJQkRkXIra++jp82sjpnVBOYBC8zsiv1M8ypgrJktxrcZPBKcfwTICc6PBcbt5/XjIy3Nty1Mm+aXTwvBGWf4cQvjx6u0ICKVQ1mrj45wzm3A9xR6DWiF74FUJs65d5xzpwTHS51zXZ1zrZ1zg51z24Pz24LXrYP3o59o+oIL/CP9Qw+FcvmUFLj2WvjyS41yFpHKoaxBIT0YlzAImOKc2wlU/172zZrBwIF+etPt20NJYtAgPxfftdf6SVpFRKJU1qDwALAMqAm8a2YHARvCylSlctFFsGYNvPRSKJdPSfHVR4sXw5NPhpKEiEiZ2f625ZpZWpHxBpHIy8tzM2fODDeR3buhdWto0QLeeSeUJJyDvDy/1sKXX0J6WceKi4jsBzOb5ZzLK+m9sjY01zWz22ODxszsNnypofpLSfGlhX//GxYtCiUJM7juOvj669CaL0REyqSs1UePAhuBM4NtA/BYWJmqdM47z09/MWFCaEkMGAC9e/spMLQ6m4hEpaxB4RDn3DVBz6GlzrlrgYPDzFil0rgxDB8Ojz0Gq1eHkoSZX8P5hx/gL38JJQkRkX0qa1DYambHxl6Y2THA1nCyVEldcYXvgXTXXaEl0b49XHgh3H03/N//hZaMiEipyhoULgbuNbNlwbQV9wAXhZaryqhNGz/a7N57Yf360JL5y18gK8uv0iYikmhlnebic+dce6Ad0M451xE/l1Fyueoq2LAhtLUWwC/l8Oc/+ymXpk0LLRkRkRJVpEvqf51zLeKcn3JJSJfU4k44wS+d9vXXkJkZShLbt8MRR/gSw5w5fsYNEZF4qXCX1NKuW4HvVl3jxsF338ETT4SWRI0acOutMH++Xy5aRCRRKhIUqv80FyXp0we6dIFbbgl1FrtBg3xS6qIqIom016BgZhvNbEMJ20bgwATlsXIx86WFJUvghRdCTeaOO3wX1euuCy0ZEZGf2WtQcM7Vds7VKWGr7ZxL3pruQYPgsMPgppv8HBUhiXVRveceP/2FiEjYKlJ9lLxSUuDKK+Gzz+DNN0NN6vrrITsbLr001PgjIgIoKOy/YcP81No33RRqMo0bw803w9tv+wHVIiJhUlDYXzVqwNixMGMGfPxxqEmNHAm9evkBbatWhZqUiCQ5BYWK+O1voX59X8cTopQUP3vq1q0walSoSYlIklNQqIjatf2cSK+8Au+/H2pShx4K11zjOzyFtN6PiMj+j2iuDCIZ0Vzcli1+EZ5WrXxgsPDG9O3cCV27+olaFyyAevVCS0pEqrGwRjQL+K5B114LH3wAL78calLp6fDwwz4oXHFFqEmJSJJSUIiH887z4xauvhp2hbtCaefOvsH54Yd9G7eISDwpKMRDWhrceKNfrvPxx0NPbvx4OOQQ3869ZUvoyYlIElFQiJdBg6B7d98aHPIvdXa27420ZImfG0lEJF4UFOLFzI8y+/bbUNdyjunTBy66CG6/Hd56K/TkRCRJKCjEU69ecMopfpTzunWhJ3f77XD44XDOObBmTejJiUgSCC0omFmmmX1iZp+b2XwzuzY438rMPjazxWb2rJllBOdrBK8XB++3DCtvobrxRr862403hp5UdjY884yfWvu88zQ3kohUXJglhe1A32AZzw7Ar82sO3AzcIdzrjXwI3BB8PkLgB+D83cEn6t62raF4cPh7rvhm29CT659e78gz9SpPkkRkYoILSg4b1PwMj3YHH5t538G5ycCg4Lj/OA1wfv9zEIcCRama6/1bQwJagW+7DI49VQ/dmHOnIQkKSLVVKhtCmaWamZzgO+BN4ElwE/OuVhn/hVAs+C4GbAcIHh/PZBTwjVHmtlMM5u5prJWpLdoAZdf7pfs/M9/Qk/ODB59FHJy4OyzYfPm0JMUkWoq1KDgnCtwznUAcoGuwOFxuOaDzrk851xeo0aNKnq58Pz5z9C8OVx8sZ+fImQNG8KTT8L//Z+PRyIi+yMhvY+ccz8BM4CjgXpmFlu1LRdYGRyvBJoDBO/XBcLvwhOWWrV8Jf+8eXDnnQlJsm9fP6j6kUfguecSkqSIVDNh9j5qZGb1guMsoD+wEB8czgg+NhyITRg0JXhN8P7brirP1geQn++38eMT0ugMPqnu3f1o50WLEpKkiFQjYZYUmgIzzGwu8CnwpnPuFeAqYKyZLca3GTwSfP4RICc4PxYYF2LeEmfCBF/p/z//k5A+o+np8OyzkJkJAwf67qoiImWlqbMT4bbb4A9/gBdfhNNOS0iS77/vq5P69vXLPaSl7fs7IpIcNHV21EaPhnbt/H7jxoQkeeyx8Pe/wxtvwFVXJSRJEakGFBQSIT0dHngAVq70E+YlyIUX+lqr22+HiRP3/XkREQWFROneHUaOhLvugs8+S1iyt9/uq5BGjoSPPkpYsiJSRSkoJNKNN/oBBRdfDAUFCUkyPd13T83N9c0ZK1fu+zsikrwUFBKpfn0/ZuGTT+CWWxKWbE6OXyl00ya/7IMW5hGR0igoJNrZZ8NZZ/l5kT79NGHJtm0LTz0Fs2bBGWckZJC1iFRBCgqJZgb33QdNm8KwYf7xPUEGDoT774fXXoMRI2D37oQlLSJVhIJCFOrXh3/8AxYvhjFjEpr0yJHw17/C00/7OZKq8DAVEQmBgkJUjjsOxo2Dhx/2g9oSaNw4GDsW7rkH/vKXhCYtIpWcgkKUxo+HvDw/UVECuwWZwd/+5tcCuuYauPfehCUtIpWcgkKUMjJ86++2bf4XOoGV/CkpvpAycCCMGuWX9RQRUVCI2qGH+m6q06fDHXckNOm0NJg0CXr2hHPPhSlTEpq8iFRCCgqVwYUX+gEEV18NCZ7gLyvLB4OOHeH007UOg0iyU1CoDMzgoYd8N9XTToPvvkto8nXrwltv+Zk4hgzxq4iKSHJSUKgsGjb0w47XrfOP7Nu3JzT5OnXg9dehTx/fvPHAAwlNXkQqCQWFyqRDB3j8cfjgA7jssoQPIqhZ06+9cPLJfnqmBK0iKiKViIJCZXPmmfCnP/mFlu+5J+HJZ2b6YROnn+7H1d14Y8KzICIRUlCojK67zvcVHTPG90pKsIwM3ytp2DD44x/9Ij2aEkMkOSgoVEYpKX4ajMMO8yWHpUsTnoW0NL8wzyWX+AldzzxTs6uKJAMFhcqqTh3fV9Q5X2pI0DKeRaWm+tHOt9/uq5T69El4xygRSTAFhcrskEPg2Wdh4UI/33WCeySB7y07Zgy89BLMmwfduvm9iFRPCgqVXf/+fgzDtGm+kn/XrkiykZ8P773nk+/RA954I5JsiEjIFBSqgvPP93U4L7zg576OqNW3Uyf4+GNfgDn5ZN85SlNvi1QvCgpVxZgxfrW2xx7z815H9Gucm+tLDAMG+In0hg6NpLlDREKioFCVjB/vV8a56y7fbTUitWrB5Ml+sZ7nnvOzf8+dG1l2RCSOFBSqEjNfjTRihA8QEQ45Tknx8/e9/bYvKXTrBo8+quokkapOQaGqSUnxDc+xIccPPxxpdo47Dj77DI45Bi64wMerzZsjzZKIVEBoQcHMmpvZDDNbYGbzzezy4HwDM3vTzL4K9vWD82ZmE8xssZnNNbNOYeWtyktL84vz/PrXftW222+PNDtNmvjeSOPH+zF3XbokfAZwEYmTMEsKu4DfO+eOALoDl5nZEcA4YLpzrg0wPXgNcBLQJthGAveFmLeqr0YNX7E/eDD8/vd+PooI625SU/3SntOmwYYNfhru//3fSIZWiEgFhBYUnHOrnHOzg+ONwEKgGZAPTAw+NhEYFBznA0847yOgnpk1DSt/1UKNGn4dzYsu8jPXXXwxFBREmqXjj/eD2845B264wTdCz54daZZEpBwS0qZgZi2BjsDHQBPn3Krgre+AJsFxM2B5ka+tCM4Vv9ZIM5tpZjPXrFkTXqaritRUuO8+X1J48EE4++zIH8/r1fM9Z195xS8P0bWrL0Xs2BFptkSkDEIPCmZWC3gB+J1zbkPR95xzDihXnYdz7kHnXJ5zLq9Ro0ZxzGkVZuYfy2+7Df75TzjlFNi0KepccfLJMH++H8tw3XU+OHz0UdS5EpG9CTUomFk6PiA85Zx7MTi9OlYtFOy/D86vBJoX+XpucE7KauxYv0jPjBl+9roVK6LOEfXr++U9X34Z1qyBo4/2A7S//37f3xWRxAuz95EBjwALnXNFu8dMAYYHx8OBl4ucPzfohdQdWF+kmknKavhwP3vdokXQuTO8+27UOQL8RK+LFsGVV8KTT8Khh8Ldd0c2lZOIlCLMksIxwDlAXzObE2wDgJuA/mb2FXB88BrgVWApsBh4CLg0xLxVb6ee6icpqlcP+vWrNJMU1a4NN9/sRz937QqjR/v5lCpJ3BIRwFwl+LHYX3l5eW6mOsSXbv163w3oX/+Cc8+F+++HrKyocwX4GDV5sh9/98038JvfwPXXw69+FXXORKo/M5vlnMsr6T2NaK7O6tb1v7zjx/uK/WOPhf/+N+pcAb5t/LTTYMECuPZaePNNaNsWzjsPli2LOnciyUtBobpLSfH9QV9+GRYv9u0ML7+87+8lSHa2n/x16VJfanjmGd/eMHo0rF4dde5Eko+CQrIYOBA++cTPfT1okJ+kaP36qHNVqGFDuPVWH7dGjIC//92v23DVVbBK3Q1EEkZBIZkcdphvgP7f//WTFB11lJ/mtBLJzfVj8BYs8HHs1luhZUu/ttBXX0WdO5HqT0Eh2WRkwF/+Ah984Bud+/XzazRs2RJ1zn7m0EPh6afhyy99O8MTT/iYNniwJtsTCZOCQrLq1s3PeT1qFEyYUGn7hrZu7TtNLVvmq5KmTfOzsPbt61cn3bkz6hyKVC8KCsksO9sHhLfegm3b/OIIQ4ZUipHQxR1wgJ/zb/lyuOUWWLIEzjjDVy1dey18+23UORSpHhQUxFchLVjgeylNnuzraf76Vx8oKpk6deCKK3xvpSlToF073+O2RQtftTR9OuzeHXUuRaouBQXxsrP9r+vChX7xnj/9CY480v/yVsIBjqmpfuD2a6/5BugxY3yb+fHHQ6tWPvuLFkWdS5GqR0FBfq5lS19ZP22aX68hP9+XJN57L+qclap1a/jb33yt11NPwRFHwE03+dHR3br5WT7Wro06lyJVg4KClKx/f/j8c7jrLl+11KuXfwx///2oc1aqrCw/Tfdrr/kAcdttfmmJUaOgaVNfAHroIT9bq4iUTEFBSpee7ocWL13q14GeNw969vQB4z//iTp3e9W0qZ9JfM4cv40Z46uZRo70jdZ9+8K996qBWqQ4TYgnZbdli+8fevPNfkGEPn180Dj1VF/JX8k55ws/L7zgt4UL/RxMXbrASSfBgAF++dAUPSpJNbe3CfEUFKT8Nm/2wWHCBD/B3kEHwWWXwQUXQIMGUeeuzBYsgBdfhFdf9SvCOQeNGsGJJ/oA0b+/n35DpLpRUJBw7NrleyfdfTe8846v1B82DP7nf6B9+6hzVy7r1vm29Vdfhddf39Mw3a6dLxD16eOHcdSrF2k2ReJCQUHC98UXvpvPP/4BW7f6X9NzzvGD4Zo1izp35VJQALNm+TF9M2b4tvVt23y1UseO0Ls39OjhlxZt2jTq3IqUn4KCJM4PP/j5r5980tfJmPlW3XPO8Svp1K4ddQ7Lbft2P4/gjBl+LMTHH/tz4Hvw9uixJ0i0beunlxKpzBQUJBqLF/vg8OSTfl6KzEzfrfXUU+GUU+DAA6PO4X7Zvt33aPrggz1brBdTRoYvJHXu7ButO3f2YwAVKKQyUVCQaDnnH6+fecYvDfr11/58Xp6fH/vUU30bhFm0+dxPzvk5mT780Fc7xbbYchUZGX5A3VFH+a1dO79v2rTK3rJUcQoKUnk4B/Pn++AwZYoPFrFuP717+xbd3r3h8MOr9C+mc75wNGsWzJ4Nc+f6ZpeVK/d8JifHB4vDD/ejrw8/3G8HHaRusRIuBQWpvFav9kOQ337bV9rHZmht0sQHh2OP9QMJ2rf31U9V3A8/+OAQCxILF/o5mopOw5GZCW3a+JXnWrf++b5FiyoxJEQqOQUFqRpij9fvvOMDxIwZe9biTE/39S5dukDXrr6y/rDD/PxM1cDatX5BoYUL/bZ4sd+WLNnTqA2QlgbNm/vSRMuWfjvoIL81b+47emVlRXUXUi7OwY4dvrfetm2l74sfx7aTTvL/H+wHBQWpmmKV9Z9+6rdPPvHLrm3c6N9PTfWP1G3b+tbctm19fczBB1eLUgX4acC//XZPkFi6FL75xi86tGyZj5nF/xfOyfHLmsa2Aw/0U3s0beq3Aw7wBbH09CjuqJLbudP/AG/ZUr598ePiW+y92A987Lgiv7/33guXXrpfX1VQkOpj927/SP35534upvnz/X7Jkj3/g5n5R+ZDDvn51ry5/5Vs2rTa/CJu3+7j5rJlvr1ixYpfbiXNEGvmB583buy3Jk32HDdq5ANLTo4f0R07jjTOFhTs+XGN91b0urt27V/+atTw089nZZVty8ws+fXe9rEt9jotbb//ORUUpPrbutVXzi9Y4ANEbFu82LdbFGXmH5djj9KxX8RGjX6+z8nxQ5ireKljxw7/T7BqFXz3nd+vWuWnryq+/fhj6dfJzob69X0wqV8fGtTbTePaW2lUexs52VtpkLmF+plbqZuxlTrpW6mdtpVaKVvItq1kuS2k7dyKbS3hSbv4cUnbjh3lv/GUFKhZ02c8tmVl/fx1ae/FjmM/2jVr/vxc0fcyM6tczwAFBUlumzb5brDFH6Fjj9arV/t5Lkr7f6FGDR8cYlvduv5HolYtvy96nJnpP198n57un+xi+9iWkuKDVGxfdHPul9vu3f6puaRt506/7dr18+MdO0retm//xVawdTs7N25n58ZtFGzeRsGWbbitvg7btm8jbedW0nZuI71gKxluP36ogd0Y21Ky2ZaSzY60bHalZbEzI5uCjGwKamSxO7Mmu7P2/Pim1MwmpVYWKbVqklo7m7Q6fkuvm01G3Swy6tcko142qbWL/cBnZFTpHmxh2ltQ2P/yx74TfRQ4BfjeOdc2ONcAeBZoCSwDznTO/WhmBtwFDAC2ACOcc7PDypskmVq19gwSKE1BgQ8Ma9b8/LH5p5/2bLHX69f7iv7Nm33A2bzZP81WNSkpe4JWsKUGW2ZWFtTJhEa1IbPRL6suilV7FGRksZUsNrlsNhdksXFXFut3ZLFhVzbrd2Tx045sftiaxY/bs/lhUwabNhubNvGLbeP3vtCwP9LSflnTEru14jE6I8NvseOi52JbevrPj/e2FY33xeN+8S019efHlS1uhRYUgMeBe4AnipwbB0x3zt1kZuOC11cBJwFtgq0bcF+wF0mM1NQ9lepHHln+78fqvLdv39M7JHa8ffuep/ai286d/sm/aCmgaKmgeMkhVqJITS15K/4LFTuOlVSK/+JVoE76F/98QK1gq6jdu/0/2+bNe+Lt5s0lt+du2VJyB52i/ymK7tev31NIKrovepxoe/tPWtqWkuJXzz3rrPjnJ7Sg4Jx718xaFjudD/QOjicC7+CDQj7whPN1WR+ZWT0za+qcWxVW/kTiKjXVl0hqxeNnMbmlpOypBWrUKLFpO+fje/GatlhtXNFtx46fx/eitXYFBb98Boi9H3uvpH1ZtlgNYliz1IdZUihJkyI/9N8BTYLjZsDyIp9bEZz7RVAws5HASIAWLVqEl1MRSTpme6p2srOjzk00ImsyD0oF5W7lds496JzLc87lNUr0Y4SISDWX6KCw2syaAgT774PzK4HmRT6XG5wTEZEESnRQmAIMD46HAy8XOX+ued2B9WpPEBFJvDC7pD6Db1RuaGYrgGuAm4DnzOwC4BvgzODjr+K7oy7Gd0k9L6x8iYhI6cLsfTSklLf6lfBZB1wWVl5ERKRsqtbYbBERCZWCgoiIFFJQEBGRQlV6QjwzW4NvsN4fDYESJhWu9pL1viF57133nVzKct8HOedKHOhVpYNCRZjZzNJmCazOkvW+IXnvXfedXCp636o+EhGRQgoKIiJSKJmDwoNRZyAiyXrfkLz3rvtOLhW676RtUxARkV9K5pKCiIgUo6AgIiKFkjIomNmvzexLM1scLAtaLZnZo2b2vZnNK3KugZm9aWZfBfv6UeYxDGbW3MxmmNkCM5tvZpcH56v1vZtZppl9YmafB/d9bXC+lZl9HPy9P2tmGVHnNQxmlmpmn5nZK8Hran/fZrbMzL4wszlmNjM4V6G/86QLCmaWCtyLXxf6CGCImR0Rba5C8zjw62LnYutktwGmB6+rm13A751zRwDdgcuC/8bV/d63A32dc+2BDsCvg6nobwbucM61Bn4ELogui6G6HFhY5HWy3Hcf51yHImMTKvR3nnRBAegKLHbOLXXO7QAm4deIrnacc+8CPxQ7nY9fH5tgPyiReUoE59wq59zs4Hgj/oeiGdX83p23KXiZHmwO6Av8Mzhf7e4bwMxygZOBh4PXRhLcdykq9HeejEGhtPWgk0Vp62RXS2bWEugIfEwS3HtQhTIHv6rhm8AS4Cfn3K7gI9X17/1O4Epgd/A6h+S4bwdMM7NZwfr1UMG/89DWU5DKzznnzKza9kk2s1rAC8DvnHMb/MOjV13v3TlXAHQws3rAS8Dh0eYofGZ2CvC9c26WmfWOODuJdqxzbqWZNQbeNLNFRd/cn7/zZCwpJPt60KWtk12tmFk6PiA85Zx7MTidFPcO4Jz7CZgBHA3UM7PYA2B1/Hs/BhhoZsvw1cF9gbuo/veNc25lsP8e/xDQlQr+nSdjUPgUaBP0TMgAzsavEZ0sSlsnu9oI6pMfARY6524v8la1vnczaxSUEDCzLKA/vj1lBnBG8LFqd9/Ouaudc7nOuZb4/5/fds4No5rft5nVNLPasWPgBGAeFfw7T8oRzWY2AF8HmQo86py7IdochaPoOtnAavw62ZOB54AWBOtkO+eKN0ZXaWZ2LPAe8AV76pj/iG9XqLb3bmbt8A2LqfgHvuecc9eZ2cH4J+gGwGfA/+ec2x5dTsMTVB/9wTl3SnW/7+D+XgpepgFPO+duMLMcKvB3npRBQURESpaM1UciIlIKBQURESmkoCAiIoUUFEREpJCCgoiIFFJQECmBmRUEM0/GtrhNnmdmLYvOXCtSmWiaC5GSbXXOdYg6EyKJppKCSDkE89ffEsxh/4mZtQ7OtzSzt81srplNN7MWwfkmZvZSsMbB52bWI7hUqpk9FKx7MC0YgYyZjQ7WgZhrZpMiuk1JYgoKIiXLKlZ9dFaR99Y7544C7sGPjAe4G5jonGsHPAVMCM5PAP4drHHQCZgfnG8D3OucOxL4CTg9OD8O6Bhc5+Jwbk2kdBrRLFICM9vknKtVwvll+IVslgaT7n3nnMsxs7VAU+fczuD8KudcQzNbA+QWnV4hmM77zWARFMzsKiDdOXe9mb0ObMJPRzK5yPoIIgmhkoJI+blSjsuj6Bw8Bexp3zsZvzJgJ+DTIrN8iiSEgoJI+Z1VZP9hcPwBfoZOgGH4CfnAL4d4CRQugFO3tIuaWQrQ3Dk3A7gKqAv8orQiEiY9hYiULCtYwSzmdedcrFtqfTObi3/aHxKcGwU8ZmZXAGuA84LzlwMPmtkF+BLBJcAqSpYKPBkEDgMmBOsiiCSM2hREyiFoU8hzzq2NOi8iYVD1kYiIFFJJQURECqmkICIihRQURESkkIKCiIgUUlAQEZFCCgoiIlLo/wfV6uiOdN5HJwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(loss_list_train, \"Blue\", label=\"Train Loss\")\n",
    "plt.plot(loss_list_valid, \"Red\", label=\"Valid Loss\")\n",
    "plt.legend(loc=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 查看损失值的损失"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 112.924339\n"
     ]
    }
   ],
   "source": [
    "print(\"Test_loss: {:4f}\".format(loss(x_test, y_test, W, B).numpy()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House ID:  83 Actual Value:  21.8 Predicted Value 23.062122\n"
     ]
    }
   ],
   "source": [
    "test_house_id = np.random.randint(0, test_num)\n",
    "y = y_test[test_house_id]\n",
    "\n",
    "y_pred = model(x_test, W, B)[test_house_id]\n",
    "y_predit = tf.reshape(y_pred, ()).numpy()\n",
    "print(\"House ID: \", test_house_id, \"Actual Value: \", y, \"Predicted Value\", y_predit)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}