{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 多元线性回归\n",
    "\n",
    "## 波士顿房价问题"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "|       |                       |         |                  |\n",
    "|:-----:|:---------------------:|:-------:|:----------------:|\n",
    "| CRIM  |        城镇人均犯罪率        |   AGE   | 1940年之前建成的自用房屋比例 |\n",
    "|  ZN   | 住宅用地超过25000 sq.ft 的比例 |   DIS   | 到波士顿5个中心区域的加权距离  |\n",
    "| INDUS |     城镇非零售商用土地的比例      |   RAD   |    辐射性公路的靠近指数    |\n",
    "| CHAS  |     边界是河流为1，否则为0      |   TAX   | 每10000美元的全值财产税率  |\n",
    "|  NOX  |        一氧化氮浓度         | PTRATIO |      城镇师生比例      |\n",
    "|  RM   |        住宅平均房间数        |  LSTAT  |   人口中地位低下者的比例    |\n",
    "|       |                       |  MEDV   | 自主房的平均房价，单位：千美元  |"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             CRIM         ZN       INDUS         CHAS         NOX          RM  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
      "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
      "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
      "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
      "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
      "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
      "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
      "\n",
      "              AGE         DIS         RAD         TAX     PTRATIO       LSTAT  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean    68.574901    3.795043    9.549407  408.237154   18.455534   12.653063   \n",
      "std     28.148861    2.105710    8.707259  168.537116    2.164946    7.141062   \n",
      "min      2.900000    1.129600    1.000000  187.000000   12.600000    1.730000   \n",
      "25%     45.025000    2.100175    4.000000  279.000000   17.400000    6.950000   \n",
      "50%     77.500000    3.207450    5.000000  330.000000   19.050000   11.360000   \n",
      "75%     94.075000    5.188425   24.000000  666.000000   20.200000   16.955000   \n",
      "max    100.000000   12.126500   24.000000  711.000000   22.000000   37.970000   \n",
      "\n",
      "             MEDV  \n",
      "count  506.000000  \n",
      "mean    22.532806  \n",
      "std      9.197104  \n",
      "min      5.000000  \n",
      "25%     17.025000  \n",
      "50%     21.200000  \n",
      "75%     25.000000  \n",
      "max     50.000000  \n"
     ]
    }
   ],
   "source": [
    "# 读取数据文件\n",
    "dateFile = pd.read_csv(\"Data/boston.csv\", header=0)\n",
    "\n",
    "# 显示数据摘要信息\n",
    "print(dateFile.describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CRIM   ZN   INDUS   CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
      "0    0.00632  18.0    2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
      "1    0.02731   0.0    7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
      "2    0.02729   0.0    7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
      "3    0.03237   0.0    2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
      "4    0.06905   0.0    2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
      "..       ...   ...     ...   ...    ...    ...   ...     ...  ...  ...   \n",
      "501  0.06263   0.0   11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
      "502  0.04527   0.0   11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
      "503  0.06076   0.0   11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
      "504  0.10959   0.0   11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
      "505  0.04741   0.0   11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
      "\n",
      "     PTRATIO  LSTAT  MEDV  \n",
      "0       15.3   4.98  24.0  \n",
      "1       17.8   9.14  21.6  \n",
      "2       17.8   4.03  34.7  \n",
      "3       18.7   2.94  33.4  \n",
      "4       18.7   5.33  36.2  \n",
      "..       ...    ...   ...  \n",
      "501     21.0   9.67  22.4  \n",
      "502     21.0   9.08  20.6  \n",
      "503     21.0   5.64  23.9  \n",
      "504     21.0   6.48  22.0  \n",
      "505     21.0   7.88  11.9  \n",
      "\n",
      "[506 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# 显示所有数据\n",
    "print(dateFile)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "      CRIM   ZN   INDUS   CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n0  0.00632  18.0    2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n1  0.02731   0.0    7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n2  0.02729   0.0    7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n\n   LSTAT  MEDV  \n0   4.98  24.0  \n1   9.14  21.6  \n2   4.03  34.7  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>LSTAT</th>\n      <th>MEDV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00632</td>\n      <td>18.0</td>\n      <td>2.31</td>\n      <td>0</td>\n      <td>0.538</td>\n      <td>6.575</td>\n      <td>65.2</td>\n      <td>4.0900</td>\n      <td>1</td>\n      <td>296</td>\n      <td>15.3</td>\n      <td>4.98</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02731</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0</td>\n      <td>0.469</td>\n      <td>6.421</td>\n      <td>78.9</td>\n      <td>4.9671</td>\n      <td>2</td>\n      <td>242</td>\n      <td>17.8</td>\n      <td>9.14</td>\n      <td>21.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.02729</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0</td>\n      <td>0.469</td>\n      <td>7.185</td>\n      <td>61.1</td>\n      <td>4.9671</td>\n      <td>2</td>\n      <td>242</td>\n      <td>17.8</td>\n      <td>4.03</td>\n      <td>34.7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只显示前3条数据\n",
    "dateFile.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "        CRIM   ZN   INDUS   CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n503  0.06076   0.0   11.93     0  0.573  6.976  91.0  2.1675    1  273   \n504  0.10959   0.0   11.93     0  0.573  6.794  89.3  2.3889    1  273   \n505  0.04741   0.0   11.93     0  0.573  6.030  80.8  2.5050    1  273   \n\n     PTRATIO  LSTAT  MEDV  \n503     21.0   5.64  23.9  \n504     21.0   6.48  22.0  \n505     21.0   7.88  11.9  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>LSTAT</th>\n      <th>MEDV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>503</th>\n      <td>0.06076</td>\n      <td>0.0</td>\n      <td>11.93</td>\n      <td>0</td>\n      <td>0.573</td>\n      <td>6.976</td>\n      <td>91.0</td>\n      <td>2.1675</td>\n      <td>1</td>\n      <td>273</td>\n      <td>21.0</td>\n      <td>5.64</td>\n      <td>23.9</td>\n    </tr>\n    <tr>\n      <th>504</th>\n      <td>0.10959</td>\n      <td>0.0</td>\n      <td>11.93</td>\n      <td>0</td>\n      <td>0.573</td>\n      <td>6.794</td>\n      <td>89.3</td>\n      <td>2.3889</td>\n      <td>1</td>\n      <td>273</td>\n      <td>21.0</td>\n      <td>6.48</td>\n      <td>22.0</td>\n    </tr>\n    <tr>\n      <th>505</th>\n      <td>0.04741</td>\n      <td>0.0</td>\n      <td>11.93</td>\n      <td>0</td>\n      <td>0.573</td>\n      <td>6.030</td>\n      <td>80.8</td>\n      <td>2.5050</td>\n      <td>1</td>\n      <td>273</td>\n      <td>21.0</td>\n      <td>7.88</td>\n      <td>11.9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只显示后3条数据\n",
    "dateFile.tail(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 获取数据集的值，df.values将以np.array形式返回数据集的值\n",
    "dataSets = dateFile.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "# 查看数据形状\n",
    "# 506行，13列的二维数组\n",
    "print(dataSets.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 4.9800e+00 2.4000e+01]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 9.1400e+00 2.1600e+01]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 4.0300e+00 3.4700e+01]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 5.6400e+00 2.3900e+01]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 6.4800e+00 2.2000e+01]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 7.8800e+00 1.1900e+01]]\n"
     ]
    }
   ],
   "source": [
    "# 查看数据集的值\n",
    "print(dataSets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 特征数据归一化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# 如有以下例子：\n",
    "# 制作一份鸡汤，需要用到鸡、水、姜、葱、蒜、盐等材料，但材料间的取值范围均不相同\n",
    "# 水的取值范围可能在2000克到3000克，但相比较之下盐可能仅需要1克2克，这样的取值范围在多元线性回归中是不合理的\n",
    "#\n",
    "# 为防止不同特征值取值范围之间的差异性，需要对特征数据进行归一化\n",
    "# 归一化过程：[特征值 / max(特征值) - min(特征值)]\n",
    "\n",
    "# x_data 为前12列特征数据\n",
    "x_data = dataSets[:, :12]  # [:, :12]表示从0~11列\n",
    "\n",
    "# y_data 为最后1列标签数据\n",
    "y_data = dataSets[:, 12]  # [:, 12]表示第12列\n",
    "\n",
    "# 对特征数据【0到11】列进行归一化（缩小差异区间至0~1）处理\n",
    "for i in range(12):\n",
    "    x_data[:, i] = x_data[:, i] / (x_data[:, i].max() - x_data[:, i].min())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.10352762e-05 1.80000000e-01 8.46774194e-02 ... 5.64885496e-01\n",
      "  1.62765957e+00 1.37417219e-01]\n",
      " [3.06957815e-04 0.00000000e+00 2.59164223e-01 ... 4.61832061e-01\n",
      "  1.89361702e+00 2.52207506e-01]\n",
      " [3.06733020e-04 0.00000000e+00 2.59164223e-01 ... 4.61832061e-01\n",
      "  1.89361702e+00 1.11203091e-01]\n",
      " ...\n",
      " [6.82927750e-04 0.00000000e+00 4.37316716e-01 ... 5.20992366e-01\n",
      "  2.23404255e+00 1.55629139e-01]\n",
      " [1.23176518e-03 0.00000000e+00 4.37316716e-01 ... 5.20992366e-01\n",
      "  2.23404255e+00 1.78807947e-01]\n",
      " [5.32876969e-04 0.00000000e+00 4.37316716e-01 ... 5.20992366e-01\n",
      "  2.23404255e+00 2.17439294e-01]] \n",
      " shape = (506, 12)\n"
     ]
    }
   ],
   "source": [
    "print(x_data, \"\\n shape =\", x_data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9] \n",
      " shape = (506,)\n"
     ]
    }
   ],
   "source": [
    "print(y_data, \"\\n shape =\", y_data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 划分数据集：训练集、验证集和测试集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# 训练集\n",
    "train_num = 300\n",
    "\n",
    "# 验证集\n",
    "valid_num = 100\n",
    "\n",
    "# 测试集 = 106 = 506 - 训练集数目 - 验证集数目\n",
    "test_num = len(x_data) - train_num - valid_num\n",
    "\n",
    "# 训练集划分（0 ~ 299）\n",
    "x_train = x_data[:train_num]\n",
    "y_train = y_data[:train_num]\n",
    "\n",
    "# 验证集划分（300 ~ 399）\n",
    "x_valid = x_data[train_num: train_num + valid_num]\n",
    "y_valid = y_data[train_num: train_num + valid_num]\n",
    "\n",
    "# 测试集划分（400 ~ 506）\n",
    "x_test = x_data[train_num + valid_num: train_num + valid_num + test_num]\n",
    "y_test = y_data[train_num + valid_num: train_num + valid_num + test_num]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# 数据类型转换，方便后面求损失函时要和变量W执行tf.matmul操作\n",
    "# 使用sklearn库中的归一化函数能起到与上面人工归一化操作一样的结果\n",
    "x_train = tf.cast(scale(x_train), dtype=tf.float32)\n",
    "x_valid = tf.cast(scale(x_valid), dtype=tf.float32)\n",
    "x_test = tf.cast(scale(x_test), dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 构建模型\n",
    "\n",
    "多元线性回归模型仍然是简单的线性函数，其基本形式还是：y = wx + b，只是此处w和b不再是一个标量，而是执行矩阵相乘，此处调用tf.matmul()函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "def model(x, w, b):\n",
    "    return tf.matmul(x, w) + b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 创建变量"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# 矩阵相乘乘数\n",
    "# 均值mean为0，标准差为1\n",
    "W = tf.Variable(tf.random.normal([12, 1], mean=0.0, stddev=1.0, dtype=tf.float32))\n",
    "\n",
    "# 偏置项\n",
    "B = tf.Variable(tf.zeros(1), dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(12, 1) dtype=float32, numpy=\n",
      "array([[ 0.84111035],\n",
      "       [-0.6557018 ],\n",
      "       [-0.19390625],\n",
      "       [-0.30917436],\n",
      "       [-1.3609434 ],\n",
      "       [ 1.0142334 ],\n",
      "       [-1.0352237 ],\n",
      "       [-0.31953537],\n",
      "       [ 0.9619099 ],\n",
      "       [ 0.65872437],\n",
      "       [-0.19516113],\n",
      "       [-0.16154423]], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(W)\n",
    "print(B)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 设置训练参数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "training_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 采用小批量梯度下降算法MBGD进行优化\n",
    "# 调整每次进行小批量训练样本数\n",
    "batch_size = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义均方差损失函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# 采用均方差作为损失函数\n",
    "def loss(x, y, w, b):\n",
    "    # 计算模型预测值与标签值的差异\n",
    "    err = model(x, w, b) - y\n",
    "\n",
    "    # 求平方，得出方差\n",
    "    squared_err = tf.square(err)\n",
    "\n",
    "    # 求均值，得出均方差\n",
    "    return tf.reduce_mean(squared_err)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义梯度计算函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# 计算样本数据[x, y]在参数[w, b]上的梯度\n",
    "def grad(x, y, w, b):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_ = loss(x, y, w, b)\n",
    "\n",
    "    # 返回梯度向量\n",
    "    return tape.gradient(loss_, [w, b])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 选择优化器"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# 创建优化器，设置学习率\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 迭代训练"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs =   1, Train_loss = 660.6848, Valid_loss = 463.0211\n",
      "Epochs =   2, Train_loss = 596.9192, Valid_loss = 412.4716\n",
      "Epochs =   3, Train_loss = 540.5432, Valid_loss = 368.7241\n",
      "Epochs =   4, Train_loss = 490.6161, Valid_loss = 330.7729\n",
      "Epochs =   5, Train_loss = 446.3626, Valid_loss = 297.8262\n",
      "Epochs =   6, Train_loss = 407.1237, Valid_loss = 269.2352\n",
      "Epochs =   7, Train_loss = 372.3283, Valid_loss = 244.4534\n",
      "Epochs =   8, Train_loss = 341.4757, Valid_loss = 223.0110\n",
      "Epochs =   9, Train_loss = 314.1229, Valid_loss = 204.4993\n",
      "Epochs =  10, Train_loss = 289.8774, Valid_loss = 188.5597\n",
      "Epochs =  11, Train_loss = 268.3902, Valid_loss = 174.8767\n",
      "Epochs =  12, Train_loss = 249.3508, Valid_loss = 163.1712\n",
      "Epochs =  13, Train_loss = 232.4832, Valid_loss = 153.1972\n",
      "Epochs =  14, Train_loss = 217.5417, Valid_loss = 144.7368\n",
      "Epochs =  15, Train_loss = 204.3082, Valid_loss = 137.5979\n",
      "Epochs =  16, Train_loss = 192.5887, Valid_loss = 131.6105\n",
      "Epochs =  17, Train_loss = 182.2112, Valid_loss = 126.6253\n",
      "Epochs =  18, Train_loss = 173.0226, Valid_loss = 122.5100\n",
      "Epochs =  19, Train_loss = 164.8874, Valid_loss = 119.1488\n",
      "Epochs =  20, Train_loss = 157.6855, Valid_loss = 116.4396\n",
      "Epochs =  21, Train_loss = 151.3103, Valid_loss = 114.2928\n",
      "Epochs =  22, Train_loss = 145.6672, Valid_loss = 112.6298\n",
      "Epochs =  23, Train_loss = 140.6724, Valid_loss = 111.3816\n",
      "Epochs =  24, Train_loss = 136.2518, Valid_loss = 110.4880\n",
      "Epochs =  25, Train_loss = 132.3396, Valid_loss = 109.8963\n",
      "Epochs =  26, Train_loss = 128.8777, Valid_loss = 109.5606\n",
      "Epochs =  27, Train_loss = 125.8143, Valid_loss = 109.4407\n",
      "Epochs =  28, Train_loss = 123.1039, Valid_loss = 109.5017\n",
      "Epochs =  29, Train_loss = 120.7060, Valid_loss = 109.7134\n",
      "Epochs =  30, Train_loss = 118.5848, Valid_loss = 110.0494\n",
      "Epochs =  31, Train_loss = 116.7085, Valid_loss = 110.4870\n",
      "Epochs =  32, Train_loss = 115.0491, Valid_loss = 111.0066\n",
      "Epochs =  33, Train_loss = 113.5817, Valid_loss = 111.5911\n",
      "Epochs =  34, Train_loss = 112.2843, Valid_loss = 112.2260\n",
      "Epochs =  35, Train_loss = 111.1374, Valid_loss = 112.8989\n",
      "Epochs =  36, Train_loss = 110.1238, Valid_loss = 113.5991\n",
      "Epochs =  37, Train_loss = 109.2280, Valid_loss = 114.3174\n",
      "Epochs =  38, Train_loss = 108.4367, Valid_loss = 115.0463\n",
      "Epochs =  39, Train_loss = 107.7378, Valid_loss = 115.7793\n",
      "Epochs =  40, Train_loss = 107.1207, Valid_loss = 116.5109\n",
      "Epochs =  41, Train_loss = 106.5761, Valid_loss = 117.2366\n",
      "Epochs =  42, Train_loss = 106.0955, Valid_loss = 117.9528\n",
      "Epochs =  43, Train_loss = 105.6718, Valid_loss = 118.6562\n",
      "Epochs =  44, Train_loss = 105.2982, Valid_loss = 119.3446\n",
      "Epochs =  45, Train_loss = 104.9692, Valid_loss = 120.0159\n",
      "Epochs =  46, Train_loss = 104.6795, Valid_loss = 120.6687\n",
      "Epochs =  47, Train_loss = 104.4246, Valid_loss = 121.3018\n",
      "Epochs =  48, Train_loss = 104.2006, Valid_loss = 121.9145\n",
      "Epochs =  49, Train_loss = 104.0038, Valid_loss = 122.5061\n",
      "Epochs =  50, Train_loss = 103.8312, Valid_loss = 123.0765\n"
     ]
    }
   ],
   "source": [
    "# 用于保存训练集loss值的列表\n",
    "loss_list_train = []\n",
    "\n",
    "# 用户保存验证集loss值的列表\n",
    "loss_list_valid = []\n",
    "\n",
    "total_step = int(train_num / batch_size)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    for step in range(total_step):\n",
    "        xs = x_train[step * batch_size: (step + 1) * batch_size, :]\n",
    "        ys = y_train[step * batch_size: (step + 1) * batch_size]\n",
    "\n",
    "        # 计算梯度\n",
    "        grads = grad(xs, ys, W, B)\n",
    "\n",
    "        # 优化器根据梯度自动调整变量W和B\n",
    "        optimizer.apply_gradients(zip(grads, [W, B]))\n",
    "\n",
    "    # 计算轮当前训练损失\n",
    "    loss_train = loss(x_train, y_train, W, B).numpy()\n",
    "\n",
    "    # 计算当前轮验证损失\n",
    "    loss_valid = loss(x_valid, y_valid, W, B).numpy()\n",
    "\n",
    "    loss_list_train.append(loss_train)\n",
    "    loss_list_valid.append(loss_valid)\n",
    "\n",
    "    print(\"Epochs = {:3d}, Train_loss = {:.4f}, Valid_loss = {:.4f}\".format(epoch + 1, loss_train, loss_valid))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 图形化损失"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x25676d84370>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(loss_list_train, \"Blue\", label=\"Train Loss\")\n",
    "plt.plot(loss_list_valid, \"Red\", label=\"Valid Loss\")\n",
    "plt.legend(loc=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 查看损失值的损失"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 114.980988\n"
     ]
    }
   ],
   "source": [
    "print(\"Test_loss: {:4f}\".format(loss(x_test, y_test, W, B).numpy()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House ID:  44 Actual Value:  10.8 Predicted Value 20.153349\n"
     ]
    }
   ],
   "source": [
    "test_house_id = np.random.randint(0, test_num)\n",
    "y = y_test[test_house_id]\n",
    "\n",
    "y_pred = model(x_test, W, B)[test_house_id]\n",
    "y_predit = tf.reshape(y_pred, ()).numpy()\n",
    "print(\"House ID: \", test_house_id, \"Actual Value: \", y, \"Predicted Value\", y_predit)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}